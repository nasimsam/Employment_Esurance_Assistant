{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce80184-f69c-4f34-a0f7-35e07557fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda,RunnablePassthrough, RunnableMap\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6ec2a5-e92e-4f3f-997b-9d14534190e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import utils\n",
    "from langsmith import traceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b315486-a234-4abf-83a1-e896879a43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# define your langchain project name here\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"EI Assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6204c90e-4327-485f-816c-8312bc84b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API = os.getenv('LANGCHAIN_API_KEY')\n",
    "mem0_API = os.getenv('mem0_API_KEY')\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Initialize your retriever (example using FAISS)\n",
    "# Load\n",
    "url = \"https://www.canada.ca/en/employment-social-development/programs/ei/ei-list/reports/digest.html\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=50, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64eb16ce-211b-4701-8467-1f2a38ddc2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Tracing is enabled: True\n"
     ]
    }
   ],
   "source": [
    "print('Is Tracing is enabled:', utils.tracing_is_enabled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a8f9ea-582d-4baa-98f1-7e9c19e6ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(api_key=OPENAI_API))\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c213cb-2aaa-46de-b6fb-88e7584effd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f18c8b2-25a4-4be2-87f4-4a39f5dd7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given User Input, Chat history and the context, determine the output.\n",
    "User Input: {input}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Chat history: {chat_history}\n",
    "\n",
    "\n",
    "How to determine the output:\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the 'Context', 'Chat history', and the 'User Input' to identify the specificity of the query and the scope of the information in 'Context'.\n",
    "\n",
    "2. If there is missing information in 'Chat history' or 'User Input', or  there is an eligibility condition in 'Context' that is not addressed in 'User Input' or 'Chat history' then a follow-up question is required, output '#'.\n",
    "   //EXAMPLES of output '#'//\n",
    "   User: I need to take care of my sick mother. Can I apply for EI?\n",
    "   User: My husband wants to get EI extended parental benefits, how does it work?\n",
    "   //END OF EXAMPLES//\n",
    "\n",
    "3. Consider 'Chat history' as a Python list. Look at the second item on the list; if it asks a question, output '~' and exit the prompt.\n",
    "\n",
    "4. Output '~' for the following cases:\n",
    "   - Look in 'Chat history' if the most recent message with 'AIMessage' tag includes a question.\n",
    "   - The user asks a general question.\n",
    "   - The user mentions that he/she can provide proof or documentation.\n",
    "   - If the user provides any information regarding his/her eligibility, output '~'.\n",
    "   - Provides information regarding the following aspects: employment status, weekly salary, and hourly rate.\n",
    "   - 'User Input' includes either \"Yes\" or \"No\".\n",
    "   //EXAMPLES of output '~'//\n",
    "   User Input: What types of EI benefits do we have?\n",
    "   User Input: My mother is critically ill. I am looking for family care benefits.\n",
    "   User Input: I am interested in a general overview of all types of EI benefits.\n",
    "   User Input: Yes. I am currently employed and worked more than 600 hours in the last 52 weeks.\n",
    "   //END OF EXAMPLES//\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9e1f24-f4fa-4ee8-be82-627ec3401559",
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        User Input: {input}\n",
    "\n",
    "        Chat history: {chat_history}\n",
    "\n",
    "        Context: {context}\n",
    "        Based on the information provided in 'context' and 'chat_history':\\\n",
    "        If there is missing information or there is a need for clarification, or there is a need for requirement verification, \\\n",
    "        then ask a follow up question to ensure that you have all the necessary information to respond effectively. \\\n",
    "        example of follow up questions:\n",
    "        //EXAMPLES//\n",
    "        User: What will be my weekly benefits or rate?\n",
    "\n",
    "        Bot: Could you please provide your weekly hours or hourly rate?\n",
    "\n",
    "        User: I need to take care of my sick mother. Can I apply for EI?\n",
    "\n",
    "        Bot: Could you please provide more details about your mother's health condition? Additionally, do you have any medical documentation available? Lastly, is your mother currently residing outside the country?\n",
    "\n",
    "        User: My husband wants to get an EI extended parental benefits, how does it work?\n",
    "\n",
    "        Bot: Have you husband worked more than 600 hours in the last 52 weeks or since his last claim? Also, is he the biological or adoptive parent of the child?\n",
    "        //END OF EXAMPLES//\n",
    "\n",
    "    Follow-Up Question:\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d2b92d9-bb3a-4437-bccb-2b0b49f280cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    provide an answer in one pharagraph based on the user's input and the context.\n",
    "\n",
    "    Chat history: {chat_history}\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a84aaf9f-5415-472e-b75b-08e4ab5a39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_chain = classification_prompt | llm_with_tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5cf904-ac46-48ad-89e8-9416268ef70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(output):\n",
    "    classification = output['classification']\n",
    "    if classification.content == \"#\":\n",
    "        return follow_up_prompt\n",
    "    else:\n",
    "        return answer_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a01440c2-d06e-487f-9f40-6c717f7897e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"context\": lambda x: x[\"context\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"classification\": lambda x: classification_chain.invoke({\"input\": x[\"input\"], \"context\": x[\"context\"], \"chat_history\": x[\"chat_history\"] }),\n",
    "    })| route\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d66555d-c188-44a6-a743-73b921218b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "import operator\n",
    "from langchain.schema import Document\n",
    "from openai import OpenAI\n",
    "from mem0 import MemoryClient\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, get_buffer_string\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "import uuid\n",
    "\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "thread_id = str(uuid.uuid4())\n",
    "openai_client = OpenAI()\n",
    "checkpointer = MemorySaver()\n",
    "nest_asyncio.apply()\n",
    "tools = [calculate_ei_benefit]\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    documents: List[Document]\n",
    "   \n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_ei_benefit(hourly_rate: float, weekly_hours: float, family_income: float = None, has_children: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the estimated weekly EI benefit.\n",
    "\n",
    "    :param hourly_rate: User's hourly wage\n",
    "    :param weekly_hours: Number of hours worked per week\n",
    "    :param family_income: Net family income (optional)\n",
    "    :param has_children: Whether the user has children (optional)\n",
    "    :return: Estimated weekly EI benefit\n",
    "    \"\"\"\n",
    "    weekly_earnings = hourly_rate * weekly_hours\n",
    "    benefit_rate = 0.55\n",
    "\n",
    "    # Check for Family Supplement eligibility\n",
    "    if family_income is not None and family_income <= 25921 and has_children:\n",
    "        benefit_rate = 0.80\n",
    "\n",
    "    weekly_benefit = weekly_earnings * benefit_rate\n",
    "    return min(weekly_benefit, 695.00)\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(state: GraphState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(f\"{get_buffer_string(messages)} {question}\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    messages = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_prompt_formatted = rag_chain.invoke({\"input\": question, \"chat_history\": messages , \"context\": formatted_docs}).text\n",
    "    generation = llm_with_tools.invoke(question)\n",
    "    return {\"documents\": documents, \"messages\": [HumanMessage(question), generation]}\n",
    "    \n",
    "tool_node = ToolNode(tools)\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "graph_builder.add_node(\"tool_node\", tool_node)\n",
    "graph_builder.add_edge(START, \"tool_node\")\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"generate_response\")\n",
    "graph_builder.add_edge(\"tool_node\", \"retrieve_documents\")\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "#simple_rag_graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "simple_rag_graph = graph_builder.compile()\n",
    "display(Image(simple_rag_graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61fe13dc-ec00-4cdd-bf0d-f7400e11dbb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No message found in input",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mCalculate my EI benefit with an hourly rate of 30, working 40 hours per week, a family income of 25000, and I have children.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msimple_rag_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m1\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\pregel\\runner.py:252\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tb := exc.__traceback__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\pregel\\runner.py:509\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    507\u001b[39m                 interrupts.append(exc)\n\u001b[32m    508\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    510\u001b[39m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\pregel\\executor.py:80\u001b[39m, in \u001b[36mBackgroundExecutor.done\u001b[39m\u001b[34m(self, task)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mself\u001b[39m.tasks.pop(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:235\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_func\u001b[39m(\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    226\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     store: Optional[BaseStore],\n\u001b[32m    234\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     tool_calls, input_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     config_list = get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[32m    237\u001b[39m     input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ei\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:441\u001b[39m, in \u001b[36mToolNode._parse_input\u001b[39m\u001b[34m(self, input, store)\u001b[39m\n\u001b[32m    439\u001b[39m     input_type = \u001b[33m\"\u001b[39m\u001b[33mdict\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo message found in input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    444\u001b[39m     latest_ai_message = \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m    445\u001b[39m         m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(messages) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, AIMessage)\n\u001b[32m    446\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No message found in input",
      "During task with name 'tool_node' and id '7dbe33e8-23a5-bde5-7574-404fa1c985f9'"
     ]
    }
   ],
   "source": [
    "question = \"Calculate my EI benefit with an hourly rate of 30, working 40 hours per week, a family income of 25000, and I have children.\"\n",
    "simple_rag_graph.invoke({\"question\": question})['messages'][1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59d422-8669-45d3-941f-43587bd89f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
